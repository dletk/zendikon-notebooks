{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Attention: AML Workspace & Auth\n",
        "> When connecting to the AML workspace, you will need to look out for the device code to do an in-browser interactive authentication.  \n",
        "The first section may not require it, but we encourage you to have an AML workspace ready for the full notebook.\n",
        "\n",
        "# Creating Azure ML pipeline with Zendikon\n",
        "\n",
        "In this example, we will be learning how to create an AML pipeline using Zendikon.\n",
        "\n",
        "The code for the pipeline steps has been provided in the `steps` folder.\n",
        "\n",
        "We will assume all steps are using the same conda environment specified in the `conda_dependencies.yml` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Running our pipeline on AML\n",
        "\n",
        "From this point on, we will require an AML workspace to work with.\n",
        "For more details on creating an AML workspace, see [Quickstart: Create workspace resources you need to get started with Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources)  \n",
        "\n",
        "**Replace the placeholder AML workspace details below with the workspace you have access to.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Experiment Setup\n",
        "\n",
        "We begin by using the AML SDK to establish the AML workspace, experiment and compute target we will be utilizing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1647441171427
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workspace name: zendikon-test\n",
            "Subscription id: 7df29d08-a878-4f14-8044-00033608a1db\n",
            "Resource group: zendikon-test\n",
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Workspace, Experiment, ComputeTarget, Dataset, Environment\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Replace these with your own AML workspace details\n",
        "subscription_id = \"7df29d08-a878-4f14-8044-00033608a1db\"\n",
        "resource_group = \"zendikon-test\"\n",
        "workspace_name = \"zendikon-test\"\n",
        "\n",
        "# Choose a name for your CPU cluster, existing ones can be used.\n",
        "cpu_cluster_name = \"zendikon-cpu-ds3\"\n",
        "\n",
        "# AML Setup\n",
        "workspace = Workspace(\n",
        "      subscription_id=subscription_id,\n",
        "      resource_group=resource_group,\n",
        "      workspace_name=workspace_name\n",
        ")\n",
        "print('Workspace name: ' + workspace.name,\n",
        "      'Subscription id: ' + workspace.subscription_id,\n",
        "      'Resource group: ' + workspace.resource_group, sep='\\n')\n",
        "\n",
        "experiment_name = \"Simple_AML_Pipeline\"\n",
        "experiment = Experiment(workspace=workspace, name=experiment_name)\n",
        "\n",
        "# Verify that the cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=workspace, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4, \n",
        "                                                           idle_seconds_before_scaledown=2400)\n",
        "    compute_target = ComputeTarget.create(workspace, cpu_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create the step class for each of the step in the pipeline\n",
        "\n",
        "We manage steps in Zendikon by creating a class representing that step. Having a class managing each step allows you to reuse the step as many time as needed in a pipeline, in different pipelines, as well as dynamically change the steps configuration later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1647441492833
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from zendikon.pipelines.step.base_step import BasePipelineStep\n",
        "\n",
        "# ================ PIPELINE STEPS SET UP =================================\n",
        "\n",
        "LoadDataStep = BasePipelineStep.create_step_class(\n",
        "    source_directory=\"./steps\", script_name=\"load_data.py\", class_name=\"LoadDataStep\")\n",
        "PreprocessDataStep = BasePipelineStep.create_step_class(\n",
        "    source_directory=\"./steps\", script_name=\"preprocess_data.py\", class_name=\"PreprocessDataStep\")\n",
        "TrainModelStep = BasePipelineStep.create_step_class(\n",
        "    source_directory=\"./steps\", script_name=\"train.py\", class_name=\"TrainModelStep\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the steps for the pipeline\n",
        "\n",
        "After having the step class, we can put them together into a pipeline with the configuration we desire.\n",
        "\n",
        "Notice: We are not specifying any input datasets for the pipeline as well as the first step in the pipeline. This is because in the `load data step`, we actually download the dataset we want to use from `sklearn` in the code. Please look into  `steps/load_data.py` for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from zendikon.pipelines.pipeline import PipelineStepInfo, Pipeline\n",
        "from zendikon.pipelines.step.step_config import StepConfig\n",
        "# ================ PIPELINE SET UP ==============\n",
        "\n",
        "steps_info = [\n",
        "    PipelineStepInfo(LoadDataStep,\n",
        "                     StepConfig(\"load data step\", inputs=[], outputs=[\"raw_features\", \"targets\"], arguments={\"active\": True, \"ratio\": 0.7}, conda_dependencies_file=\"./conda_dependencies.yml\")),\n",
        "    PipelineStepInfo(PreprocessDataStep,\n",
        "                     StepConfig(\"preprocess data step\", inputs=[\"raw_features\"], outputs=[\"processed_features\"], conda_dependencies_file=\"./conda_dependencies.yml\")),\n",
        "    PipelineStepInfo(TrainModelStep,\n",
        "                     StepConfig(\"train a model\", inputs=[\"processed_features\", \"targets\"], outputs=[\"predicted\"], conda_dependencies_file=\"./conda_dependencies.yml\"))\n",
        "]\n",
        "pipeline = Pipeline(input_datasets=[], compute_targets=[compute_target], steps_info=steps_info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Submit Pipeline\n",
        "In order to submit the pipeline, in the first submission, you will need to specify `add_zendikon_feed=True` and `personal_access_token`. This will allow Zendikon package to be installed from Zendikon feed to your pipeline when the pipeline is running on your AML workspace. This only need to be done once! After the first submission, you can specify `add_zendikon_feed=False` (default setting) and leave `personal_access_token` to be `None`.\n",
        "\n",
        "The pipeline will now execute remotely on our specified compute target, and we can track the progress in AML Studio with the generated link below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1647441500559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created step load data step [67f02983][a52df852-6188-4b53-a588-0225dbc44ca2], (This step is eligible to reuse a previous run's output)\n",
            "Created step preprocess data step [e7ffa6fe][230263cd-d68c-43b1-84b0-a063a075e145], (This step is eligible to reuse a previous run's output)\n",
            "Created step train a model [4ac81f96][d95ef809-a9bc-422b-8422-83d0bf32b32a], (This step is eligible to reuse a previous run's output)\n",
            "Submitted PipelineRun 16deab2d-ef61-4bc8-9d9a-11b99a665633\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/16deab2d-ef61-4bc8-9d9a-11b99a665633?wsid=/subscriptions/7df29d08-a878-4f14-8044-00033608a1db/resourcegroups/zendikon-test/workspaces/zendikon-test&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Simple_AML_Pipeline</td><td>16deab2d-ef61-4bc8-9d9a-11b99a665633</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/16deab2d-ef61-4bc8-9d9a-11b99a665633?wsid=/subscriptions/7df29d08-a878-4f14-8044-00033608a1db/resourcegroups/zendikon-test/workspaces/zendikon-test&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: Simple_AML_Pipeline,\n",
              "Id: 16deab2d-ef61-4bc8-9d9a-11b99a665633,\n",
              "Type: azureml.PipelineRun,\n",
              "Status: Running)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline.submit(experiment, wait_for_completion=False, add_zendikon_feed=True, personal_access_token=\"<YOUR PAT>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('zendikon37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f518ce44f98f045a778dd62beacc4c6bd6975e54f1df8536bc21feb807c48a8e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
